# Veena_Portfolio
Complete Developer Portfolio 

# Project 1
Amazon reviews: Document Term Matrix for Amazon Reviews and then building models to predict the ratings given by the customers. Text mining was performed using NLTK library package and RegEx libraries. Built neural network models such as RNN, CNN and LSTM machine learning models to classify the reviews and predict the ratings of each review. Clustering was done in order to check if reviews with same rating fall under same clusters K-means clustering, UMAP and HDSCAN

1 million Amazon reviews were tokenized, stop words were removed, stemming was performed on this data and created Bag of words. Most of the other data sets Null values were modified or whole rows were dropped if 70% of the columns are missing for those rows. The null values are often replaced with column means or max or min depending on the application. Number of rows and columns with the missing values haves been checked for most of the data sets.

#Project 2
Bird Species Classification: Classification of 11788 bird images into 200 classes. Classified using VGG16 and VGG19 pre trained models. Also, classified the birds using basic CNN and Dense neural network models. Able to get accuracy of 96% with Xception pretrained model.

#Project 3

Lives of Americans with multiple jobs: Analyze the lives or satisfaction levels of people with single job when compared to those with multiple jobs. ATUS survey data was used. Python and R programming languages were used to clean and analyze the data. Seminar was presented on the findings. Tableau and JMP was used for graphs and data insights. 

#Project 4

LEAN PROJECT: Facilitate international students at UNH with timely, accurate information and streamline logistic operations.

#Project 5

Online survey was conducted to collect data from international students with respect to problems they are face while applying to UNH and after they arrive at UNH,19 questions were posted, and 58 responses were collected out of 430 international students. Descriptive statistical analysis was performed on the collected data. Deep insights and graphs made in Power BI, Tableau and JMP.

#Project 6

Worked on structured, unstructured and mixed raw data and analyzed data using statistical tools such as Jmp Pro, Tableau, Power BI, Python and R

Analyzed and mined business Data to identify patterns and correlations among the various Data points for marketing data. 

Developed forecasting models for forecasting daily, weekly, and monthly operational performance. 

Performed segmentation analysis on Kirin’s marketing data. Created Dendrograms and analyzed the profile for each segment and suggested Kirin which segment to target based on the analysis. 

Created confusion matrix and classification reports.

Survey was conducted to collect Lyft and Uber user experience data. Both the data were compared and derived insights on the data. Performed SWOT and STP analysis. Analyzed Dendrograms and Scree plots to provide segmentation solution. Conjoint analysis was performed and provided features in order to grow Lyft’s business. 

Lyft’s majority of customer bases is working class professional, college students and over 43% of Lyft users are between the age group of 18-45.  Food delivery service was suggested to the Lyft to increase their revenue and market value.
Excelled at SQL as large data sets were merged and processed using SQL query programming during internship at Fresh Air Sensor and River Stone.

Statistical programming, modelling of data, Data mining, Data Cleaning and Data processing and bulding data pipelines in Python, SAS, R.

MS Office Suite for writing reports, analyzing data using Excel and power point presentations have been heavily used throughout the master’s program and at previous organizations. 

#Project 7 (AWS)
Large data sets were added to Amazon server and used SageMaker, python and R libraries that amazon web services provide to implement machine learning models. AWS servers are 10 times faster and handle large amount of data.

Developed data pipelines for incrementally loading the data. Optimize the running data pipelines and ensure reliability and availability.

while performing data visualization in Tableau or Power BI using data from big data repositories, most of the time these applications crash. Have used in-memory data models to solve these issues.

#Project 8
•	Created and worked on Mango DB and hive on a project used Hadoop and SQL queries, Pyspartk in order to access and modify the large data sets in the data base. Used Map-Reduce functions to process these big data.

